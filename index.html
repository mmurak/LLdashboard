<html>
  <head>
    <title>LLdashboard（Ver. 0.8）</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" >
    <link rel="shortcut icon" href="kiwi-bird.png">
    <link rel="stylesheet" href="./scripts/LLdashboard.css">
  </head>
  <body style="user-select: none;">
    <div class="tooltip">
    <input type="file" id="AudioFile" onclick="this.value=null;" accept=".mp3,.mp4,.ogg"/></input>
    <div class="tooltiptext">モデル音源ファイルを指定します。<br/>データはメモリに展開するため、あまり大きな（再生時間の長い）ファイルは指定しないようにしてください。</div>
    </div>
    <br/>
    <div class="tooltip">
    <label>Splitter：</label>
    <div class="tooltiptext">有音部を抽出するためのパラメータです。<br/>・threshold: 無音と有音を区別する信号のしきい値（0.0〜1.0）<br/>・Min blank: 切れ目と認識する最少無音時間（秒単位）<br/>・Min sound: 有音と認識する最少有音時間（秒単位）</div>
    </div>
    <label> threshold: <input type="text" id="Threshold" value="0.011" size="6"></input></label>
    <label>Min blank (sec.): <input type="text" id="MinBlank" value="0.8" size="5"></label>
    <label>Min sound (sec.): <input type="text" id="MinSound" value="0.2" size="5"></input></label>
    <input type="button" id="SplitButton" value="Split"></input>
    <label id="SplittedValue"></label>
    <select id="Selector" name="selector"></select>
    <input type="button" id="SampleSoundPlayButton" value="Play Audio Snippet" disabled="true"></input>
    <input type="button" id="NextSampleSoundPlayButton" value="Play Next Clip" disabled="true"></input>
    <br/>
    <div class="tooltip">
    Low Pass Filter: 
    <div class="tooltiptext">イントネーションを見やすくするためにCutoff frequencyを超える音域を除去します（QはQuality factor）。<br/>・none: 音声、画像ともフィルタを通さない<br/>・Visualiser only: 画像のみフィルタを通す<br/>・both: 音声、画像ともフィルタを通す</div>
    </div>
    <label><select id="FilterUsage"><option value="0">none</option><option value="1" selected>Visualiser only</option><option value="2">both</option></select></label>
    <label>Cutoff frequency: <label id="FilterCOfLabel"></label></label><label>Hz</label><input type="range" id="FilterCOf" min="100" max="5000" value="200" oninput="cutoffFreqChange(this.value);"></label>
    <label>Q: <input type="text" id="FilterQ" value="50" size="5"></label>
    <br/>
    <div class="tooltip">
    <label>Spectrogram:</label>
    <div class="tooltiptext">縦軸を周波数、横軸を時間軸で表示します。<br/>音圧は256段階で黒〜青〜黄〜白へと遷移し、黒から色づき始める音圧をMinimum levelで、取り扱う音圧の幅をDynamic Rangeで指定します（上限を超える音圧は白で、下限を下回る音圧は黒で表示されます）。</div>
    </div>
    </label> Range: <select id="FFTsize"><option value="512">〜15,000Hz+</option><option value="1024">〜8,000Hz</option><option value="2048">〜4,000Hz</option><option value="4096">〜2,000Hz</option><option value="8192">〜1,000Hz</option><option value="16384" selected>〜500Hz</option></select></label>
    <label>Min. level: <label id="FFTminDecLabel"></label><label>dB</label><input type="range" id="FFTminDec" min="-150" max="-1" value="-90" oninput="fftMinDecChange(this.value);"></label>
    <label>Dynamic Range: <label id="FFTDynRangeLabel"></label></label><label>dB</label><input type="range" id="FFTDynRange" min="1" max="150" value="60" oninput="fftDynRangeChange(this.value);"></label>
    <label>Smoothing TC: <input type="textfield" id="FFTsmooth" value="0.8" size="5"></label>
    <br/>
    <div class="tooltip">
    <label>Pixels/Process</label>
    <div class="tooltiptext">単位時間あたりの横スクロールピクセル数です。</div>
    </div>
    <label><select id="PixelSpeed"><option value="1">1</option><option value="2" selected>2</option><option value="3">3</option></select></label>
    <br/>
    <canvas id="Spectrogram" width="800" height="200"></canvas>
    <br/>
    <div class="tooltip">
    <label>Stressgram:</label>
    <div class="tooltiptext">ストレス表示に使用する周波数範囲です。この周波数範囲の音圧の平均値をストレスとして表示します。</div>
    </div>
    <label>Lower Limit: </label><label id="LowerBoundaryLabel"></label><input type="range" id="LowerBoundary" min="50" max="300" value="170" oninput="stressLowerBoundaryChange(this.value);">
    <label>Upper Limit: </label><label id="UpperBoundaryLabel"></label><input type="range" id="UpperBoundary" min="50" max="300" value="225" oninput="stressUpperBoundaryChange(this.value);">
    <br/>
    <canvas id="Stressgram" width="800" height="100"></canvas>
    <hr>
    <canvas id="Indicator" width="40" height="20"></canvas>
    <input type="button" id="RecordButton" value="Record" onClick="recButton();">
    <input type="button" id="UserSoundPlayButton" value="Play Recorded Sound" onClick="playIt();" disabled="true"> | 
    <input type="button" id="SaveButton" value="Save" onClick="saveSound();" disabled="true">
    <br/>
    <label>Minimum dB: <label id="FFT2minDecLabel"></label><input type="range" id="FFT2minDec" min="-150" max="-1" value="-90" oninput="fft2MinDecChange(this.value);"></label>
    <label>Dynamic Range (dB): <label id="FFT2DynRangeLabel"></label><input type="range" id="FFT2DynRange" min="1" max="150" value="60" oninput="fft2DynRangeChange(this.value);"></label>
    <label>Smoothing TC: <input type="textfield" id="FFT2smooth" value="0.8" size="5"></label>
    <br/>
    <canvas id="Spectrogram2" width="800" height="200"></canvas>
    <br/>
    <label>Lower Limit: </label><label id="LowerBoundaryLabel2"></label><input type="range" id="LowerBoundary2" min="50" max="300" value="170" oninput="stressLowerBoundaryChange2(this.value);">
    <label>Upper Limit: </label><label id="UpperBoundaryLabel2"></label><input type="range" id="UpperBoundary2" min="50" max="300" value="225" oninput="stressUpperBoundaryChange2(this.value);">
    <br/>
    <canvas id="Stressgram2" width="800" height="100"></canvas>

<script src="./scripts/AudioSplitter.js"></script>
<script src="./scripts/Smoother.js"></script>
<script src="./scripts/Visualiser.js"></script>
<script src='./scripts/lame.all.js'></script>

<script>
/*
 * Globals for widgets
 */
const AudioFile = document.getElementById("AudioFile");
const Threshold = document.getElementById("Threshold");
const MinBlank = document.getElementById("MinBlank");
const MinSound = document.getElementById("MinSound");
const SplitButton = document.getElementById("SplitButton");
const SplittedValue = document.getElementById("SplittedValue");
const Selector = document.getElementById("Selector");
const FilterUsage = document.getElementById("FilterUsage");
const FilterCOf = document.getElementById("FilterCOf");
const FilterCOfLabel = document.getElementById("FilterCOfLabel");
const FilterQ = document.getElementById("FilterQ");
const FFTsize = document.getElementById("FFTsize");
const FFTminDec = document.getElementById("FFTminDec");
const FFTminDecLabel = document.getElementById("FFTminDecLabel");
const FFTDynRange = document.getElementById("FFTDynRange");
const FFTDynRangeLabel = document.getElementById("FFTDynRangeLabel");
const FFTsmooth = document.getElementById("FFTsmooth");
const PixelSpeed = document.getElementById("PixelSpeed");
const LowerBoundary = document.getElementById("LowerBoundary");
const LowerBoundaryLabel = document.getElementById("LowerBoundaryLabel");
const UpperBoundary = document.getElementById("UpperBoundary");
const UpperBoundaryLabel = document.getElementById("UpperBoundaryLabel");
const SampleSoundPlayButton = document.getElementById("SampleSoundPlayButton");
const NextSampleSoundPlayButton = document.getElementById("NextSampleSoundPlayButton");
const Spectrogram = document.getElementById("Spectrogram");
const Stressgram = document.getElementById("Stressgram");
const Indicator = document.getElementById("Indicator");
const RecordButton = document.getElementById("RecordButton");
const UserSoundPlayButton = document.getElementById("UserSoundPlayButton");
const SaveButton = document.getElementById("SaveButton");
const FFT2minDec = document.getElementById("FFTminDec");
const FFT2minDecLabel = document.getElementById("FFT2minDecLabel");
const FFT2DynRange = document.getElementById("FFT2DynRange");
const FFT2DynRangeLabel = document.getElementById("FFT2DynRangeLabel");
const FFT2smooth  = document.getElementById("FFTsmooth");
const Spectrogram2 = document.getElementById("Spectrogram2");
const LowerBoundary2 = document.getElementById("LowerBoundary2");
const LowerBoundaryLabel2 = document.getElementById("LowerBoundaryLabel2");
const UpperBoundary2 = document.getElementById("UpperBoundary2");
const UpperBoundaryLabel2 = document.getElementById("UpperBoundaryLabel2");
const Stressgram2 = document.getElementById("Stressgram2");

/*
 * Globals
 */
const AnAudioContext = new AudioContext();
const TrailingSec = 0.3;
let AnAudioSplitter;
let AnSplittedAudioArray = [];
let ARecorder;
let Chunks;
let SampleSourceNode;
let InPlay = false;
let InRec = false;
let IndicatorCtx = Indicator.getContext("2d");

/*
 * Internal functions
 */
function _setFFTValues() {
    FFTminDecLabel.innerHTML = FFTminDec.value;
    FFTDynRangeLabel.innerHTML = FFTDynRange.value;
    FFT2minDecLabel.innerHTML = FFT2minDec.value;
    FFT2DynRangeLabel.innerHTML = FFT2DynRange.value;
}
function _setSplittedAudioNumber() {
    SplittedValue.innerHTML = AnSplittedAudioArray.length;
}
function _setCutoffFrequency() {
    FilterCOfLabel.innerHTML = FilterCOf.value;
}
function _setBoundaryHz() {
    LowerBoundaryLabel.innerHTML = LowerBoundary.value + "Hz";
    UpperBoundaryLabel.innerHTML = UpperBoundary.value + "Hz";
    LowerBoundaryLabel2.innerHTML = LowerBoundary2.value + "Hz";
    UpperBoundaryLabel2.innerHTML = UpperBoundary2.value + "Hz";
}

function _getAudioBuffer(url, func) {
    let xhr = new XMLHttpRequest();
    xhr.responseType = 'arraybuffer';
    xhr.onreadystatechange = function () {
        if (xhr.readyState !== 4) {
            return;
        }
        AnAudioContext.decodeAudioData(xhr.response, function (audioBuffer) {
            func(audioBuffer);
        });
    };
    xhr.open('GET', url, true);
    xhr.send();
}

function _readFile2Buffer(url) {
    _getAudioBuffer(url, function (audioBuffer) {
        AnAudioSplitter = new AudioSplitter(audioBuffer, 0, TrailingSec);
        splitAudio(Number(Threshold.value), Number(MinBlank.value), Number(MinSound.value));
        _setSplittedAudioNumber();
        SampleSoundPlayButton.disabled = false;
        NextSampleSoundPlayButton.disabled = false;
    });
}

function _successFunc(stream) {
    ARecorder = new MediaRecorder(stream);

    ARecorder.addEventListener('dataavailable', function(ele) {
        if (ele.data.size > 0) {
            Chunks.push(ele.data);
        }
    });
}

function _setIndicator(value) {
    if (value == 0) {
        IndicatorCtx.fillStyle ="#87ceeb";
    } else {
        IndicatorCtx.fillStyle = "rgb(255, 0, 0)";
    }
    IndicatorCtx.fillRect(0, 0, Indicator.width, Indicator.height);
}



/*
 * Initialisation processes
 */
_setFFTValues();
_setSplittedAudioNumber();
_setCutoffFrequency();
_setBoundaryHz();
_setIndicator(0);

navigator.mediaDevices.getUserMedia(
    {
        audio: true,
    })
    .then (_successFunc)
    .catch(function (err) {
        alert(err);
    }
);



/*
 * Widgets Controls
 */
// Sample file input
AudioFile.addEventListener("change", function(evt) {
    let url = window.URL.createObjectURL(evt.target.files[0]);
    _readFile2Buffer(url);
}, false);

SplitButton.addEventListener("click", function() {
    splitAudio(Number(Threshold.value), Number(MinBlank.value), Number(MinSound.value));
    _setSplittedAudioNumber();
});

SampleSoundPlayButton.addEventListener("click", function(evt) {
    playPortion();
});

NextSampleSoundPlayButton.addEventListener("click", function() {
    let num = Selector.value;   // Get the specfied audio snippet
    if (num < AnSplittedAudioArray.length - 1) {
        num++;
        Selector.value = num;
        playPortion();
    }
});

// Cutoff Frequency
function cutoffFreqChange(value) {
    FilterCOfLabel.innerHTML = value;
}

// FFT range control
function fftMinDecChange(value) {
    FFTminDecLabel.innerHTML = value;
}
function fftDynRangeChange(value) {
    FFTDynRangeLabel.innerHTML = value;
}
function fft2MinDecChange(value) {
    FFT2minDecLabel.innerHTML = value;
}
function fft2DynRangeChange(value) {
    FFT2DynRangeLabel.innerHTML = value;
}

function stressLowerBoundaryChange(value) {
    value = Number(value);
    let limit = Number(UpperBoundary.value);
    if (value >= limit) {
        value = limit - 1;
        LowerBoundary.value = value;
    }
    LowerBoundaryLabel.innerHTML = value + "Hz";
}

function stressUpperBoundaryChange(value) {
    value = Number(value);
    let limit = Number(LowerBoundary.value);
    if (value <= limit) {
        value = limit + 1;
        UpperBoundary.value = value;
    }
    UpperBoundaryLabel.innerHTML = value + "Hz";
}

function stressLowerBoundaryChange2(value) {
    value = Number(value);
    let limit = Number(UpperBoundary2.value);
    if (value >= limit) {
        value = limit - 1;
        LowerBoundary2.value = value;
    }
    LowerBoundaryLabel2.innerHTML = value + "Hz";
}

function stressUpperBoundaryChange2(value) {
    value = Number(value);
    let limit = Number(LowerBoundary2.value);
    if (value <= limit) {
        value = limit + 1;
        UpperBoundary2.value = value;
    }
    UpperBoundaryLabel2.innerHTML = value + "Hz";
}

function splitAudio(threshold, minBlank, minSound) {
    AnSplittedAudioArray = AnAudioSplitter.splitWith(threshold, minBlank, minSound);
    while(Selector.firstChild) {
        Selector.removeChild(Selector.lastChild);
    }
    for (let i = 0; i < AnSplittedAudioArray.length; i++) {
        let elem = document.createElement("option");
        elem.value = i;
        let textNo = i + 1;
        let seconds = Math.floor((AnSplittedAudioArray[i][1] - AnSplittedAudioArray[i][0]) * 100 / AnAudioSplitter.sampleRate) / 100;
        elem.text = textNo + " (" + seconds + ")";
        Selector.appendChild(elem);
    }
}

function _makeLPF(ftype, freq, q) {
    let lpf = new BiquadFilterNode(AnAudioContext, { frequency: freq, q: q});
    lpf.ftype = ftype;
    return lpf;
}

// Play sample
function playPortion() {
    if (InPlay) {
        InPlay = false;
        SampleSoundPlayButton.value = "Play Audio Snippet";
        RecordButton.disabled = false;
        UserSoundPlayButton.disabled = false;
        SampleSourceNode.stop();
        return;
    }
    InPlay = true;
    SampleSoundPlayButton.value = "Stop Playing Audio Snippet";
    NextSampleSoundPlayButton.disabled = true;
    RecordButton.disabled = true;
    UserSoundPlayButton.disabled = true;
    let num = Selector.value;   // Get the specfied audio snippet
    let bufp = AnAudioSplitter.getBufferPortion(AnAudioContext, 2, AnSplittedAudioArray[num][0], AnSplittedAudioArray[num][1]);
    SampleSourceNode = AnAudioContext.createBufferSource();
    SampleSourceNode.buffer = bufp;

    let splitter = AnAudioContext.createChannelSplitter(2);

    // Create Low Pass Filters
    let bqf1 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));
    let bqf2 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));
    let bqf3 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));

    // Initialise spectrogram
    let maxDecibel = Number(FFTminDec.value) + Number(FFTDynRange.value);
    let aVisualiser = new Visualiser(Spectrogram, Stressgram,
                                    AnAudioContext,
                                    FFTsize.value, Number(FFTminDec.value), maxDecibel, Number(FFTsmooth.value),
                                    Number(PixelSpeed.value),
                                    LowerBoundary.value, UpperBoundary.value,
                                    [{r: 0, g: 0, b: 255}, {r: 255, g: 255, b: 0}]);

    SampleSourceNode.addEventListener("ended", function() {
        aVisualiser.stopRendering();
        SampleSoundPlayButton.value = "Play Audio Snippet";
        InPlay = false;
        NextSampleSoundPlayButton.disabled = false;
        RecordButton.disabled = false;
        UserSoundPlayButton.disabled = false;
    }.bind(aVisualiser));

    switch (FilterUsage.value) {
    case "1" :
        SampleSourceNode.connect(splitter);
        splitter.connect(AnAudioContext.destination, 0);
        splitter.connect(bqf1, 1).connect(bqf2).connect(bqf3).connect(aVisualiser.analyser);
        break;
    case "2" :
        SampleSourceNode.connect(bqf1).connect(bqf2).connect(bqf3).connect(splitter);
        splitter.connect(AnAudioContext.destination, 0);
        splitter.connect(aVisualiser.analyser, 1);
        break;
    default :
        SampleSourceNode.connect(splitter);
        splitter.connect(AnAudioContext.destination, 0);
        splitter.connect(aVisualiser.analyser, 1);
    }

    aVisualiser.startRendering();

    // Start Playing
    SampleSourceNode.start();
}

function recStart() {
    UserSoundPlayButton.disabled = true;
    SampleSoundPlayButton.disabled = true;
    NextSampleSoundPlayButton.disabled = true;
    Chunks = [];
    ARecorder.start();
}

function recStop() {
    ARecorder.stop();
    UserSoundPlayButton.disabled = false;
    SampleSoundPlayButton.disabled = false;
    NextSampleSoundPlayButton.disabled = false;
}

function recButton() {
    if (InRec) {
        InRec = false;
        _setIndicator(0);
        RecordButton.value = "Record";
        SaveButton.disabled = false;
        recStop();
    } else {
        InRec = true;
        _setIndicator(1);
        RecordButton.value = "Push to Stop";
        SaveButton.disabled = true;
        recStart();
    }
}

function playIt() {
    SampleSoundPlayButton.disabled = true;
    NextSampleSoundPlayButton.disabled = true;
    RecordButton.disabled = true;
    SaveButton.disabled = true;
    UserSoundPlayButton.disabled = true;
    let fileReader = new FileReader();
    fileReader.onloadend = () => {      // 2. Invoked when loadend the Blob (Get the ArrayBuffer)
        let arrayBuffer = fileReader.result;
        AnAudioContext.decodeAudioData(arrayBuffer, (audioBuffer) => {        // 3. convert to AudioBuffer
//
            let oldBufData = audioBuffer.getChannelData(0);         // 4. Get the Float32 data
            // 5. Double the channel (preparation for split)
            let sampleRate = AnAudioContext.sampleRate;
            let newBuffer = AnAudioContext.createBuffer(2, oldBufData.length + (TrailingSec * sampleRate), sampleRate);
            for (let ch = 0; ch < 2; ch++) {
                let newBufData = newBuffer.getChannelData(ch);
                for (let i = 0; i < newBufData.length; i++) {
                    newBufData[i] = 0.0;
                }
                for (let i = 0; i < oldBufData.length; i++) {
                    newBufData[i] = oldBufData[i];
                }
            }
//
            let source = AnAudioContext.createBufferSource();
            source.buffer = newBuffer;
            // Graphical process
            let splitter = AnAudioContext.createChannelSplitter(2);
            let visualiserSource = AnAudioContext.createBufferSource();
            let lpf1 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));
            let lpf2 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));
            let lpf3 = _makeLPF("lowpass", Number(FilterCOf.value), Number(FilterQ.value));

            let maxDecibel = Number(FFT2minDec.value) + Number(FFT2DynRange.value);
            let s = new Visualiser(Spectrogram2, Stressgram2,
                                AnAudioContext,
                                FFTsize.value, Number(FFT2minDec.value), maxDecibel, Number(FFT2smooth.value),
                                Number(PixelSpeed.value),
                                LowerBoundary2.value, UpperBoundary2.value,
                                [{r: 0, g: 0, b: 255}, {r: 255, g: 255, b: 0}]);
            source.addEventListener("ended", function() {
                s.stopRendering();
                SampleSoundPlayButton.disabled = false;
                NextSampleSoundPlayButton.disabled = false;
                RecordButton.disabled = false;
                UserSoundPlayButton.disabled = false;
                SaveButton.disabled = false;
            }.bind(s));

            switch (FilterUsage.value) {
                case "1" :
                    source.connect(splitter);
                    splitter.connect(lpf1,1).connect(lpf2).connect(lpf3).connect(s.analyser);
                    splitter.connect(AnAudioContext.destination, 0);
                    break;
                case "2" :
                    source.connect(lpf1).connect(lpf2).connect(lpf3).connect(splitter);
                    splitter.connect(AnAudioContext.destination, 0);
                    splitter.connect(s.analyser);
                    break;
                default :
                    source.connect(splitter);
                    splitter.connect(AnAudioContext.destination, 0);
                    splitter.connect(s.analyser, 1);
            }

            s.startRendering();
            source.start();
        });
    }
    fileReader.readAsArrayBuffer(new Blob(Chunks, { 'type' : 'audio/ogg; codecs=opus' }));  // 1. Chunks->Blob
}

function saveSound() {
    let url = window.URL.createObjectURL(new Blob(Chunks, { 'type' : 'audio/ogg; codecs=opus' }));
/*
    let link = document.createElement("a");
    link.href = url;
    link.download = "output.webm";
    link.click();
*/
    _saveBuffer(url);
}

function _convertFl32toInt16(buff) {
    let val = new Int16Array(buff.length);
    for (let i = 0; i < buff.length; i++) {
        val[i] = Math.floor(buff[i] * 32768);
    }
    return val;
}

function _saveBuffer(url) {
    _getAudioBuffer(url, function (audioBuffer) {
        let buff32 = new Float32Array(audioBuffer.length);
        buff32.set(audioBuffer.getChannelData(0));
        mp3encoder = new lamejs.Mp3Encoder(1, AudioContext.sampleRate, 128);
        let mp3Data = [];
        let samples = _convertFl32toInt16(buff32);
        let sampleBlockSize = 1152;
        for (let i = 0; i < samples.length; i += sampleBlockSize) {
            let sampleChunk = samples.subarray(i, i + sampleBlockSize);
            let mp3buf = mp3encoder.encodeBuffer(sampleChunk);
            if (mp3buf.length > 0) {
                mp3Data.push(mp3buf)
            }
        }
        let mp3buf = mp3encoder.flush();
        if (mp3buf.length > 0) {
            mp3Data.push(new Int8Array(mp3buf));
        }
        let blob = new Blob(mp3Data, {type: 'audio/mp3'});
        let url = window.URL.createObjectURL(blob);
        let link = document.createElement("a");
        link.href = url;
        link.download = "output.mp3";
        link.click();
    });
}

</script>
</body>
</html>
